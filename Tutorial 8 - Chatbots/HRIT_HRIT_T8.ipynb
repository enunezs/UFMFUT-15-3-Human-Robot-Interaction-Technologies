{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb5YpOmpk-4b"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd-et3eykBtt",
        "outputId": "8f8ed580-7a3c-4aee-d27a-2aa9adc46669"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (3.9.2)\n",
            "Requirement already satisfied: spacy in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (3.8.11)\n",
            "Requirement already satisfied: contractions in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (0.1.73)\n",
            "Requirement already satisfied: numpy in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (1.26.4)\n",
            "Requirement already satisfied: SpeechRecognition in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (3.14.4)\n",
            "Requirement already satisfied: gtts in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (2.5.4)\n",
            "Requirement already satisfied: pygame in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (2.6.1)\n",
            "Requirement already satisfied: openai in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (2.8.1)\n",
            "Requirement already satisfied: click in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from spacy) (2.32.5)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from spacy) (2.12.4)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from spacy) (65.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.5)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: colorama in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: wrapt in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: anyascii in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.3)\n",
            "Requirement already satisfied: pyahocorasick in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from textsearch>=0.0.21->contractions) (2.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\enune\\downloads\\ufmfut-15-3-human-robot-interaction-technologies-main\\.venv\\lib\\site-packages (from jinja2->spacy) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk spacy contractions numpy SpeechRecognition gtts pygame openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRc8D03_khCx",
        "outputId": "70bbbd94-69c3-415c-c9c1-30a2b3d21813"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
        "!pip install PyAudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Yq-JtCi0Mb"
      },
      "source": [
        "# Speech Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "mD43RYtxi1ah",
        "outputId": "41afb0bf-ea6b-4c0c-9fa1-1e3303e254f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pygame 2.6.1 (SDL 2.28.4, Python 3.11.9)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ]
        },
        {
          "ename": "PermissionError",
          "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'response.mp3'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     62\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[43mspeak\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHello, I am your voice assistant. How can I help you?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     58\u001b[39m         command = listen()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mspeak\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m pygame.mixer.music.get_busy():\n\u001b[32m     23\u001b[39m     pygame.time.Clock().tick(\u001b[32m10\u001b[39m)  \u001b[38;5;66;03m# Check every 100 ms\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtts_file\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mPermissionError\u001b[39m: [WinError 32] The process cannot access the file because it is being used by another process: 'response.mp3'"
          ]
        }
      ],
      "source": [
        "import speech_recognition as sr\n",
        "import pyaudio\n",
        "from gtts import gTTS\n",
        "import os\n",
        "import pygame\n",
        "\n",
        "# Initialize the recognizer\n",
        "recognizer = sr.Recognizer()\n",
        "\n",
        "def speak(text):\n",
        "    # Use Google Text-to-Speech to convert text to speech\n",
        "    tts = gTTS(text=text, lang='en')\n",
        "    tts_file = 'response.mp3'\n",
        "    tts.save(tts_file)\n",
        "\n",
        "    # Initialize pygame for playing audio\n",
        "    pygame.mixer.init()\n",
        "    pygame.mixer.music.load(tts_file)\n",
        "    pygame.mixer.music.play()\n",
        "\n",
        "    # Wait until the audio is finished playing\n",
        "    while pygame.mixer.music.get_busy():\n",
        "        pygame.time.Clock().tick(10)  # Check every 100 ms\n",
        "\n",
        "    os.remove(tts_file)  # Remove the file after playing\n",
        "\n",
        "def listen():\n",
        "    with sr.Microphone() as source:\n",
        "        print(\"Listening...\")\n",
        "        audio = recognizer.listen(source)\n",
        "        try:\n",
        "            command = recognizer.recognize_google(audio)\n",
        "            print(f\"You said: {command}\")\n",
        "            return command.lower()\n",
        "        except sr.UnknownValueError:\n",
        "            speak(\"Sorry, I didn't understand that.\")\n",
        "            return None\n",
        "        except sr.RequestError:\n",
        "            speak(\"Could not request results from the speech recognition service.\")\n",
        "            return None\n",
        "\n",
        "def process_command(command):\n",
        "    if command:\n",
        "        if \"hello\" in command:\n",
        "            speak(\"Hello! How can I assist you today?\")\n",
        "        elif \"your name\" in command:\n",
        "            speak(\"I am your voice assistant.\")\n",
        "        elif \"bye\" in command:\n",
        "            speak(\"Goodbye! Have a great day!\")\n",
        "            return False  # To exit the loop\n",
        "        else:\n",
        "            speak(\"I can only respond to simple greetings for now.\")\n",
        "    return True  # To continue the loop\n",
        "\n",
        "def main():\n",
        "    speak(\"Hello, I am your voice assistant. How can I help you?\")\n",
        "    while True:\n",
        "        command = listen()\n",
        "        if command is None:  # If there was an error in recognition\n",
        "            continue\n",
        "        if not process_command(command):\n",
        "            break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "2gas7wR4II0E",
        "outputId": "762e4d07-e34a-4a39-f9ea-7e923d81b399"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "No Default Input Device Available",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-fa8c4e00086c>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mrecognize_speech_from_mic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-fa8c4e00086c>\u001b[0m in \u001b[0;36mrecognize_speech_from_mic\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Set up the microphone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMicrophone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mmic\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, device_index, sample_rate, chunk_size)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mdevice_index\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Device index out of range ({} devices available; device index should be between 0 and {} inclusive)\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# automatically set the sample rate to the hardware's default sample rate if not specified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mdevice_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_info_by_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_input_device_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"defaultSampleRate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdevice_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"defaultSampleRate\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Invalid device info returned from PyAudio: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"defaultSampleRate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyaudio/__init__.py\u001b[0m in \u001b[0;36mget_default_input_device_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m         \"\"\"\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0mdevice_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_input_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_info_by_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: No Default Input Device Available"
          ]
        }
      ],
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "def recognize_speech_from_mic():\n",
        "    # Create a Recognizer instance\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Set up the microphone\n",
        "    mic = sr.Microphone()\n",
        "\n",
        "    with mic as source:\n",
        "        print(\"Adjusting for ambient noise. Please wait...\")\n",
        "        recognizer.adjust_for_ambient_noise(source)\n",
        "        print(\"Listening...\")\n",
        "        audio = recognizer.listen(source, timeout=5, phrase_time_limit=10)\n",
        "\n",
        "    try:\n",
        "        # Recognize speech using Google Web Speech API\n",
        "        print(\"Recognizing...\")\n",
        "        # Set timeout to 5 seconds and phrase_time_limit to 10 seconds\n",
        "        # You can adjust here!\n",
        "        text = recognizer.recognize_google(audio)\n",
        "        print(\"You said: \" + text)\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Sorry, I could not understand the audio.\")\n",
        "    except sr.RequestError as e:\n",
        "        print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    recognize_speech_from_mic()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewv-mWp-INQf"
      },
      "source": [
        "# Speech Synthesis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "BfXgSoULIOLa",
        "outputId": "46a0be24-899b-4ad3-b9e6-d1bcbb16753c"
      },
      "outputs": [
        {
          "ename": "error",
          "evalue": "ALSA: Couldn't open audio device: No such file or directory",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-593c615b4b7c>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0msample_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Hello! This is a sample text to demonstrate speech synthesis using Python.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mtext_to_speech\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-593c615b4b7c>\u001b[0m in \u001b[0;36mtext_to_speech\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Initialize pygame mixer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmusic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmusic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: ALSA: Couldn't open audio device: No such file or directory"
          ]
        }
      ],
      "source": [
        "from gtts import gTTS\n",
        "import os\n",
        "import pygame\n",
        "\n",
        "def text_to_speech(text, language='en'):\n",
        "    # Create a gTTS object\n",
        "    tts = gTTS(text=text, lang=language, slow=False)\n",
        "\n",
        "    # Save the audio file\n",
        "    audio_file = \"output.mp3\"\n",
        "    tts.save(audio_file)\n",
        "\n",
        "    # Initialize pygame mixer\n",
        "    pygame.mixer.init()\n",
        "    pygame.mixer.music.load(audio_file)\n",
        "    pygame.mixer.music.play()\n",
        "\n",
        "    # Wait until the audio is finished playing\n",
        "    while pygame.mixer.music.get_busy():\n",
        "        pygame.time.Clock().tick(10)  # Check every 100 ms\n",
        "\n",
        "    # Optionally, remove the audio file after playing\n",
        "    os.remove(audio_file)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    sample_text = \"Hello! This is a sample text to demonstrate speech synthesis using Python.\"\n",
        "    text_to_speech(sample_text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
